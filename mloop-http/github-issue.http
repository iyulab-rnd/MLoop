@host = https://localhost:7102
@scenarioId = 68d4fa5974da492c9e7c452dc73c05c4
@jobId = ec18b72071fc4a059a5fcad069794163
### 1. 시나리오 생성
POST {{host}}/api/scenarios
Content-Type: application/json

{
    "name": "GitHub Issue Classification",
    "mlType": "classification",
    "tags": ["github", "issue", "classification"]
}

### 시나리오 가져오기
GET {{host}}/api/scenarios/{{scenarioId}}

### 2. 훈련 데이터 업로드 
POST {{host}}/api/scenarios/{{scenarioId}}/data
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary

------WebKitFormBoundary
Content-Disposition: form-data; name="files"; filename="issues_train.tsv"
Content-Type: text/tab-separated-values

< ..\files\GitHubIssueClassification\issues_train.tsv
------WebKitFormBoundary--

### 3. 테스트 데이터 업로드
POST {{host}}/api/scenarios/{{scenarioId}}/data
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary

------WebKitFormBoundary
Content-Disposition: form-data; name="files"; filename="issues_test.tsv"
Content-Type: text/tab-separated-values

< ..\files\GitHubIssueClassification\issues_test.tsv
------WebKitFormBoundary--

### 4. 데이터 파일 목록 확인
GET {{host}}/api/scenarios/{{scenarioId}}/data

### 5. 기본 학습 워크플로우 업데이트
PUT {{host}}/api/scenarios/{{scenarioId}}/workflows/default_train
Content-Type: text/yaml

name: default_train
type: Train
steps:
  - name: classify_issues
    type: mlnet-train
    config:
      command: classification
      args:
        # 필수 설정
        dataset: issues_train.tsv
        validation-dataset: issues_test.tsv
        label-col: Area
        
        # 옵션 설정
        has-header: true
        allow-quote: true
        train-time: 120
        ignore-cols: ID 

### 워크플로우 가져오기
GET {{host}}/api/scenarios/{{scenarioId}}/workflows/default_train

### 6. 워크플로우 목록 확인
GET {{host}}/api/scenarios/{{scenarioId}}/workflows

### 7. 모델 학습 시작
POST {{host}}/api/scenarios/{{scenarioId}}/train

### 8. 학습 작업 목록 확인
GET {{host}}/api/scenarios/{{scenarioId}}/jobs

### 8. 학습 작업 상태 확인`
GET {{host}}/api/scenarios/{{scenarioId}}/jobs/{{jobId}}

### 8. 학습 로그 확인
GET {{host}}/api/scenarios/{{scenarioId}}/jobs/{{jobId}}/logs

### 9. 학습된 모델 목록 확인
GET {{host}}/api/scenarios/{{scenarioId}}/models

### 10. 예측 요청
POST {{host}}/api/scenarios/{{scenarioId}}/predict
Content-Type: text/tab-separated-values

Python Programming	How to Handle Large JSON Files Efficiently in Python?	I'm working on a Python project to process large JSON files (several GB). Loading the entire file into memory with json.load() causes crashes. I need an efficient way to extract specific keys and values without loading the full file. How can I handle large JSON files line by line or in chunks?

### 11. 예측 결과 확인 (predictionId는 이전 응답에서 받은 것으로 교체)
@jobId = c2df618a442941c48c8177c375ec084a
GET {{host}}/api/scenarios/{{scenarioId}}/predictions/{{jobId}}

###
GET {{host}}/api/scenarios/{{scenarioId}}/jobs/{{jobId}}/logs

###
GET {{host}}/api/scenarios/{{scenarioId}}/predictions